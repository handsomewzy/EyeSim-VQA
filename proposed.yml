name: IntraRef
num_epochs: 10
l_num_epochs: 5
warmup_epochs: 2.5
ema: true
save_model: true
batch_size: 4
num_workers: 6
split_seed: 42

wandb:
    project_name: vis_test
    # Proposed_test_dualhead+1dyt LVSQ_dualhead+1dyt kvq-dualhead-cleannet+basvir-10clips vis_test
data:   
    val-livevqc:
        type: ViewDecompositionDataset
        args:
            weight: 0.598
            phase: test
            anno_file: ./examplar_data_labels/LIVE_VQC/labels.txt
            data_prefix: /data1/userhome/luwen/Code/wzy/VQA_dataset/LIVE Video Quality Challenge (VQC) Database/
            sample_types:
                technical:
                    fragments_h: 7
                    fragments_w: 7
                    fsize_h: 32
                    fsize_w: 32
                    aligned: 32
                    clip_len: 32
                    frame_interval: 2
                    num_clips: 3
                aesthetic:
                    size_h: 224
                    size_w: 224
                    clip_len: 32
                    frame_interval: 2
                    t_frag: 32
                    num_clips: 1
                    
    val-kv1k:
        type: ViewDecompositionDataset
        args:
            weight: 0.540
            phase: test
            anno_file: ./examplar_data_labels/KoNViD/labels.txt
            data_prefix: /data1/userhome/luwen/Code/wzy/VQA_dataset
            sample_types:
                technical:
                    fragments_h: 7
                    fragments_w: 7
                    fsize_h: 32
                    fsize_w: 32
                    aligned: 32
                    clip_len: 32
                    frame_interval: 2
                    num_clips: 3
                aesthetic:
                    size_h: 224
                    size_w: 224
                    clip_len: 32
                    frame_interval: 2
                    t_frag: 32
                    num_clips: 1

    val-ltrain:
        type: ViewDecompositionDataset
        args:
            weight: 0.603
            phase: train
            anno_file: ./examplar_data_labels/train_labels.txt
            data_prefix: /data1/userhome/luwen/Code/wzy/VQA_dataset/LSVQ
            sample_types:
                technical:
                    fragments_h: 7
                    fragments_w: 7
                    fsize_h: 32
                    fsize_w: 32
                    aligned: 32
                    clip_len: 32
                    frame_interval: 2
                    num_clips: 3
                aesthetic:
                    size_h: 224
                    size_w: 224
                    clip_len: 32
                    frame_interval: 2
                    t_frag: 32
                    num_clips: 1

    val-ltest:
        type: ViewDecompositionDataset
        args:
            weight: 0.603
            phase: test
            anno_file: ./examplar_data_labels/LSVQ/labels_test_refresh.txt
            data_prefix: /data1/userhome/luwen/Code/wzy/VQA_dataset/LSVQ
            sample_types:
                technical:
                    fragments_h: 7
                    fragments_w: 7
                    fsize_h: 32
                    fsize_w: 32
                    aligned: 32
                    clip_len: 32
                    frame_interval: 2
                    num_clips: 3
                aesthetic:
                    size_h: 224
                    size_w: 224
                    clip_len: 32
                    frame_interval: 2
                    t_frag: 32
                    num_clips: 1

    val-l1080p:
        type: ViewDecompositionDataset
        args:
            weight: 0.620
            phase: test
            anno_file: ./examplar_data_labels/LSVQ/labels_1080p_refresh.txt
            data_prefix: /data1/userhome/luwen/Code/wzy/VQA_dataset/LSVQ
            sample_types:
                technical:
                    fragments_h: 7
                    fragments_w: 7
                    fsize_h: 32
                    fsize_w: 32
                    aligned: 32
                    clip_len: 32
                    frame_interval: 2
                    num_clips: 3
                aesthetic:
                    size_h: 224
                    size_w: 224
                    clip_len: 32
                    frame_interval: 2
                    t_frag: 32
                    num_clips: 1

    val-cvd2014:
        type: ViewDecompositionDataset
        args:
            weight: 0.576
            phase: test
            anno_file: ./examplar_data_labels/CVD2014/labels.txt
            data_prefix: ../datasets/CVD2014/
            sample_types:
                technical:
                    fragments_h: 7
                    fragments_w: 7
                    fsize_h: 32
                    fsize_w: 32
                    aligned: 32
                    clip_len: 32
                    frame_interval: 2
                    num_clips: 3
                aesthetic:
                    size_h: 224
                    size_w: 224
                    clip_len: 32
                    frame_interval: 2
                    t_frag: 32
                    num_clips: 1
                    
    val-ytugc:
        type: ViewDecompositionDataset
        args:
            weight: 0.443
            phase: test
            anno_file: /data1/userhome/luwen/Code/wzy/DOVER-master/examplar_data_labels/YouTubeUGC/labels_filtered.txt
            data_prefix: /data1/userhome/luwen/Code/wzy/VQA_dataset/YouTube_original_videos_h264
            sample_types:
                technical:
                    fragments_h: 7
                    fragments_w: 7
                    fsize_h: 32
                    fsize_w: 32
                    aligned: 32
                    clip_len: 32
                    frame_interval: 2
                    num_clips: 3
                aesthetic:
                    size_h: 224
                    size_w: 224
                    clip_len: 32
                    frame_interval: 2
                    t_frag: 32
                    num_clips: 1


    val-kvq:
        type: ViewDecompositionDataset
        args:
            weight: 0.540
            phase: test
            anno_file: /data1/userhome/luwen/Code/wzy/DOVER-master/examplar_data_labels/KVQ/KVQ_train_refresh.txt
            data_prefix: /data1/userhome/luwen/Code/wzy/VQA_dataset/KVQ/train_video-001
            # anno_file: /data1/userhome/luwen/Code/wzy/DOVER-master/examplar_data_labels/KVQ/KVQ_val.txt
            # data_prefix: /data1/userhome/luwen/Code/wzy/VQA_dataset/KVQ/Validation/val_videos
            sample_types:
                technical:
                    fragments_h: 7
                    fragments_w: 7
                    fsize_h: 32
                    fsize_w: 32
                    aligned: 32
                    clip_len: 32
                    frame_interval: 2
                    num_clips: 3
                aesthetic:
                    size_h: 224
                    size_w: 224
                    clip_len: 32
                    frame_interval: 2
                    t_frag: 32
                    num_clips: 1
                    





model:
    type: IntraRef
    args:
        backbone:
            # 经典的SwinTrans，不带mamba
            technical:
                type: swin_tiny_grpb
                checkpoint: true
                pretrained: ./pretrained_weights/DOVER.pth

            # 加入mamba模块，先扫描再注意力
            # technical:
            #     type: swin_3d_mamba
            #     checkpoint: true
            #     pretrained: ./pretrained_weights/DOVER.pth

            aesthetic:
                type: conv_tiny
        backbone_preserve_keys: technical,aesthetic
        divide_head: true
        vqa_head:
            in_channels: 768
            hidden_channels: 64
            
optimizer:
    lr: !!float 1e-3
    backbone_lr_mult: !!float 1e-1
    wd: 0.05
        
test_load_path: ./pretrained_weights/DOVER.pth
# ./pretrained_weights/DOVER.pth

    
        
